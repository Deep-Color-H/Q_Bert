{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from C:\\Users\\LGCNS\\Documents\\GitHub\\Q_Bert\\QBert\\train_utils.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\LGCNS\\Documents\\GitHub\\Q_Bert\\QBert\\models.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from copy import deepcopy\n",
    "\n",
    "import import_ipynb\n",
    "from QBert import train_utils, models\n",
    "\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 해당 파일은 bert.run_pretraining.run_bert_pretrain을 구현하는 것을 목표로 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Parameter는 FLAG 형식에서 직접 정의해주는 방식으로 변경하고, Main에서 직접 정의하도록 한다."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Strategy 정의\n",
    "2. Input_Files 정의\n",
    "3. Bert Config 정의\n",
    "   - bert_config (1. Core_Model - Transformer Encoder - Sub Model)\n",
    "        - vocab_size\n",
    "        - type_vocab_size\n",
    "        - hidden_size\n",
    "        - max_seq_length\n",
    "        - initializer\n",
    "        - kernel_initializer\n",
    "        - initializer_range\n",
    "        - dropout_rate\n",
    "        - num_attention_heads\n",
    "        - intermediate_size\n",
    "        - intermediate_activation\n",
    "        - hidden_act\n",
    "        - attention_dropout_rate\n",
    "        - num_hidden_instances\n",
    "        - pooled_output_dim\n",
    "   - bert_config (2. Pretrained_Model - input to losses)\n",
    "        - (중복 생략)\n",
    "        - max_predictions_per_seq\n",
    "        \n",
    "3. Get Bert Model\n",
    "4. Training Config 정의\n",
    "5. Training\n",
    "6. Test\n",
    "\n",
    "\n",
    "   - init_checkpoint  # Used to initialize only the BERT submodel.\n",
    "   - max_seq_length\n",
    "   -  \n",
    "   - masked_lm\n",
    "   - model_dir\n",
    "   - num_steps_per_epoch\n",
    "   - steps_per_loop\n",
    "   - num_train_epochs\n",
    "   - learning_rate\n",
    "   - warmup_steps\n",
    "   - end_lr\n",
    "   - optimizer_type\n",
    "   - train_batch_size\n",
    "   - use_next_sentence_label\n",
    "   - train_summary_interval\n",
    "   - custom_callbacks\n",
    "   - explicit_allreduce\n",
    "   - pre_allreduce_callbacks\n",
    "   - allreduce_bytes_per_pack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['./Test_Examples.tfrecords', './Test_Examples.tfrecords']\n",
    "\n",
    "# Create a description of the features.\n",
    "feature_description = {\n",
    "    'input_ids': tf.io.FixedLenFeature([256], tf.int64),\n",
    "    'segment_ids': tf.io.FixedLenFeature([256], tf.int64),\n",
    "    'input_mask': tf.io.FixedLenFeature([256], tf.int64),\n",
    "    'masked_lm_positions': tf.io.FixedLenFeature([255], tf.int64),\n",
    "    'masked_lm_ids': tf.io.FixedLenFeature([255], tf.int64),\n",
    "    'masked_lm_weights': tf.io.FixedLenFeature([255], tf.float32),\n",
    "    'next_sentence_labels': tf.io.FixedLenFeature([1], tf.int64),\n",
    "}\n",
    "\n",
    "# keys = feature_description.keys()\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "  # Parse the input `tf.train.Example` proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_model (core_model 필요 Config)\n",
    "\n",
    "vocab_size = 32000 # \n",
    "hidden_size = 768 # Transformer hidden Layers\n",
    "type_vocab_size = 12 #: The number of types that the 'type_ids' input can take.\n",
    "num_layers = 12\n",
    "num_attention_heads = 12\n",
    "max_seq_length = 256 # 512\n",
    "dropout_rate = .1\n",
    "# attention_dropout_rate = .1\n",
    "inner_dim = 3072\n",
    "# hidden_act = 'gelu'\n",
    "initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02)\n",
    "\n",
    "# Pretrain Model 필요 Config\n",
    "max_predictions_per_seq = 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(fake_y, losses, **unused_args) :\n",
    "    \n",
    "    return tf.reduce_mean(losses, axis = -1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _select_data_from_record(record):\n",
    "    \"\"\"Filter out features to use for pretraining.\"\"\"\n",
    "    x = {\n",
    "        'input_ids': record['input_ids'],\n",
    "        'input_mask': record['input_mask'],\n",
    "        'segment_ids': record['segment_ids'],\n",
    "        'masked_lm_positions': record['masked_lm_positions'],\n",
    "        'masked_lm_ids': record['masked_lm_ids'],\n",
    "        'masked_lm_weights': record['masked_lm_weights'],\n",
    "    }\n",
    "    if use_next_sentence_label:\n",
    "        x['next_sentence_labels'] = record['next_sentence_labels']\n",
    "    if use_position_id:\n",
    "        x['position_ids'] = record['position_ids']\n",
    "\n",
    "    # TODO(hongkuny): Remove the fake labels after migrating bert pretraining.\n",
    "    if output_fake_labels:\n",
    "        return (x, record['masked_lm_weights'])\n",
    "    else:\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(filenames)\n",
    "train_dataset = train_dataset.map(_parse_function)\n",
    "\n",
    "model, sub_model = models.get_bert_models_fn(vocab_size\n",
    "             , hidden_size\n",
    "             , type_vocab_size\n",
    "             , num_layers\n",
    "             , num_attention_heads\n",
    "             , max_seq_length\n",
    "             , max_predictions_per_seq\n",
    "             , dropout_rate\n",
    "             , inner_dim \n",
    "             , initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "use_next_sentence_label = True\n",
    "output_fake_labels = True\n",
    "use_position_id = False\n",
    "\n",
    "dataset = train_dataset.map(_select_data_from_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr = 1e-3)\n",
    "\n",
    "model.compile(optimizer = optimizer, loss=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LGCNS\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8/Unknown - 70s 9s/step - loss: 11.1807 - masked_lm_accuracy: 0.0000e+00 - lm_example_loss: 10.3470 - next_sentence_accuracy: 0.5078 - next_sentence_loss: 0.8337"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[8160,32000] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[node model_6/bert_pretrain_loss_and_metric_layer_6/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <string>:49) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_118016]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-6776834085e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[8160,32000] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[node model_6/bert_pretrain_loss_and_metric_layer_6/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <string>:49) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_118016]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model.fit(dataset.batch(32), epochs = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices() # device 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "\n",
      "장치의 수: 1\n"
     ]
    }
   ],
   "source": [
    "# Strategy 정의\n",
    "\n",
    "distribution_strategy = 'mirrored' # 'tpu'\n",
    "num_gpus = 0\n",
    "all_reduce_alg = None\n",
    "\n",
    "if distribution_strategy == 'tpu' :\n",
    "    tpu_address = \"\"\n",
    "else :\n",
    "    tpu_address = None\n",
    "\n",
    "\n",
    "\n",
    "strategy = train_utils.get_distribution_strategy(\n",
    "                  distribution_strategy=distribution_strategy,\n",
    "                  num_gpus=num_gpus,\n",
    "                  all_reduce_alg=all_reduce_alg,\n",
    "                  tpu_address=tpu_address)\n",
    "\n",
    "print ('\\n장치의 수: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input_Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['./Test_Examples.tfrecords', './Test_Examples.tfrecords']\n",
    "\n",
    "# Create a description of the features.\n",
    "feature_description = {\n",
    "    'input_ids': tf.io.FixedLenFeature([256], tf.int64),\n",
    "    'segment_ids': tf.io.FixedLenFeature([256], tf.int64),\n",
    "    'input_mask': tf.io.FixedLenFeature([256], tf.int64),\n",
    "    'masked_lm_positions': tf.io.FixedLenFeature([255], tf.int64),\n",
    "    'masked_lm_ids': tf.io.FixedLenFeature([255], tf.int64),\n",
    "    'masked_lm_weights': tf.io.FixedLenFeature([255], tf.float32),\n",
    "    'next_sentence_labels': tf.io.FixedLenFeature([1], tf.int64),\n",
    "}\n",
    "\n",
    "# keys = feature_description.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'strategy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e6482d4f6e72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mBATCH_SIZE_PER_REPLICA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mGLOBAL_BATCH_SIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBATCH_SIZE_PER_REPLICA\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_replicas_in_sync\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'strategy' is not defined"
     ]
    }
   ],
   "source": [
    "def _parse_function(example_proto):\n",
    "  # Parse the input `tf.train.Example` proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "BUFFER_SIZE = 672\n",
    "\n",
    "BATCH_SIZE_PER_REPLICA = 64\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = tf.train.Example.FromString(raw_data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64_list {\n",
       "  value: 2\n",
       "  value: 7864\n",
       "  value: 18704\n",
       "  value: 255\n",
       "  value: 3684\n",
       "  value: 12\n",
       "  value: 19411\n",
       "  value: 5673\n",
       "  value: 3325\n",
       "  value: 26078\n",
       "  value: 6281\n",
       "  value: 5659\n",
       "  value: 15\n",
       "  value: 8538\n",
       "  value: 5746\n",
       "  value: 6972\n",
       "  value: 16\n",
       "  value: 13\n",
       "  value: 544\n",
       "  value: 5649\n",
       "  value: 4\n",
       "  value: 6718\n",
       "  value: 4\n",
       "  value: 12\n",
       "  value: 20\n",
       "  value: 12884\n",
       "  value: 4\n",
       "  value: 13\n",
       "  value: 18958\n",
       "  value: 3018\n",
       "  value: 6871\n",
       "  value: 4\n",
       "  value: 32\n",
       "  value: 14583\n",
       "  value: 3105\n",
       "  value: 17853\n",
       "  value: 4\n",
       "  value: 7430\n",
       "  value: 6\n",
       "  value: 541\n",
       "  value: 3091\n",
       "  value: 3273\n",
       "  value: 5661\n",
       "  value: 4334\n",
       "  value: 12\n",
       "  value: 13930\n",
       "  value: 6875\n",
       "  value: 7904\n",
       "  value: 8109\n",
       "  value: 4\n",
       "  value: 15\n",
       "  value: 8277\n",
       "  value: 14197\n",
       "  value: 3113\n",
       "  value: 13\n",
       "  value: 6\n",
       "  value: 5949\n",
       "  value: 7788\n",
       "  value: 17\n",
       "  value: 7720\n",
       "  value: 5697\n",
       "  value: 6025\n",
       "  value: 4\n",
       "  value: 532\n",
       "  value: 3018\n",
       "  value: 3473\n",
       "  value: 3022\n",
       "  value: 12\n",
       "  value: 8088\n",
       "  value: 6215\n",
       "  value: 6375\n",
       "  value: 13595\n",
       "  value: 3036\n",
       "  value: 13\n",
       "  value: 5852\n",
       "  value: 4\n",
       "  value: 4\n",
       "  value: 3090\n",
       "  value: 13912\n",
       "  value: 12\n",
       "  value: 4\n",
       "  value: 8289\n",
       "  value: 13952\n",
       "  value: 11038\n",
       "  value: 13\n",
       "  value: 6\n",
       "  value: 5978\n",
       "  value: 13122\n",
       "  value: 3091\n",
       "  value: 17444\n",
       "  value: 26094\n",
       "  value: 17\n",
       "  value: 5643\n",
       "  value: 7015\n",
       "  value: 2037\n",
       "  value: 14361\n",
       "  value: 4\n",
       "  value: 26214\n",
       "  value: 8442\n",
       "  value: 15\n",
       "  value: 5667\n",
       "  value: 2073\n",
       "  value: 11126\n",
       "  value: 12850\n",
       "  value: 4\n",
       "  value: 8506\n",
       "  value: 12138\n",
       "  value: 2037\n",
       "  value: 7740\n",
       "  value: 5858\n",
       "  value: 4\n",
       "  value: 3018\n",
       "  value: 3473\n",
       "  value: 14629\n",
       "  value: 26570\n",
       "  value: 5742\n",
       "  value: 13122\n",
       "  value: 4\n",
       "  value: 26214\n",
       "  value: 4\n",
       "  value: 5740\n",
       "  value: 4\n",
       "  value: 30333\n",
       "  value: 7021\n",
       "  value: 1727\n",
       "  value: 11761\n",
       "  value: 4\n",
       "  value: 17\n",
       "  value: 3\n",
       "  value: 6080\n",
       "  value: 5771\n",
       "  value: 7352\n",
       "  value: 3267\n",
       "  value: 27778\n",
       "  value: 3169\n",
       "  value: 2073\n",
       "  value: 20156\n",
       "  value: 21302\n",
       "  value: 7521\n",
       "  value: 28753\n",
       "  value: 4\n",
       "  value: 12426\n",
       "  value: 26637\n",
       "  value: 4\n",
       "  value: 26298\n",
       "  value: 18393\n",
       "  value: 4\n",
       "  value: 4\n",
       "  value: 6\n",
       "  value: 7990\n",
       "  value: 150\n",
       "  value: 6258\n",
       "  value: 1886\n",
       "  value: 5584\n",
       "  value: 17\n",
       "  value: 10563\n",
       "  value: 7021\n",
       "  value: 12850\n",
       "  value: 23240\n",
       "  value: 8515\n",
       "  value: 12989\n",
       "  value: 6\n",
       "  value: 5978\n",
       "  value: 10934\n",
       "  value: 4\n",
       "  value: 4\n",
       "  value: 6148\n",
       "  value: 3064\n",
       "  value: 7317\n",
       "  value: 5640\n",
       "  value: 17\n",
       "  value: 3\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "  value: 0\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed.features.feature['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(filenames)\n",
    "train_dataset = train_dataset.map(_parse_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with strategy.scope():\n",
    "\n",
    "    train_dataset = tf.data.TFRecordDataset(filenames)\n",
    "    train_dataset = train_dataset.map(_parse_function)\n",
    "    train_dataset_iters = train_dataset.shuffle(BUFFER_SIZE).batch(1) \n",
    "    \n",
    "    train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset_iters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert_Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_model (core_model 필요 Config)\n",
    "\n",
    "vocab_size = 32000 # \n",
    "hidden_size = 768 # Transformer hidden Layers\n",
    "type_vocab_size = 12 #: The number of types that the 'type_ids' input can take.\n",
    "num_layers = 12\n",
    "num_attention_heads = 12\n",
    "max_seq_length = 256 # 512\n",
    "dropout_rate = .1\n",
    "# attention_dropout_rate = .1\n",
    "inner_dim = 3072\n",
    "# hidden_act = 'gelu'\n",
    "initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02)\n",
    "\n",
    "# Pretrain Model 필요 Config\n",
    "max_predictions_per_seq = 255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'strategy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-5e7c0bdbfd92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     model, sub_model = models.get_bert_models_fn(vocab_size\n\u001b[0;32m      4\u001b[0m                  \u001b[1;33m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                  \u001b[1;33m,\u001b[0m \u001b[0mtype_vocab_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'strategy' is not defined"
     ]
    }
   ],
   "source": [
    "with strategy.scope() :\n",
    "\n",
    "    model, sub_model = models.get_bert_models_fn(vocab_size\n",
    "                                             , hidden_size\n",
    "                                             , type_vocab_size\n",
    "                                             , num_layers\n",
    "                                             , num_attention_heads\n",
    "                                             , max_seq_length\n",
    "                                             , max_predictions_per_seq\n",
    "                                             , dropout_rate\n",
    "                                             , inner_dim \n",
    "                                             , initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traning Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\LGCNS\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    C:\\Users\\LGCNS\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\LGCNS\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\LGCNS\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\LGCNS\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:541 train_step  **\n        self.trainable_variables)\n    C:\\Users\\LGCNS\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1804 _minimize\n        trainable_variables))\n    C:\\Users\\LGCNS\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:521 _aggregate_gradients\n        filtered_grads_and_vars = _filter_grads(grads_and_vars)\n    C:\\Users\\LGCNS\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:1219 _filter_grads\n        ([v.name for _, v in grads_and_vars],))\n\n    ValueError: No gradients provided for any variable: ['embedding_2/embeddings:0', 'position_embedding_1/embeddings:0', 'embedding_3/embeddings:0', 'layer_normalization_25/gamma:0', 'layer_normalization_25/beta:0', 'multi_head_attention_12/dense_72/kernel:0', 'multi_head_attention_12/dense_72/bias:0', 'multi_head_attention_12/dense_73/kernel:0', 'multi_head_attention_12/dense_73/bias:0', 'multi_head_attention_12/dense_74/kernel:0', 'multi_head_attention_12/dense_74/bias:0', 'multi_head_attention_12/dense_75/kernel:0', 'multi_head_attention_12/dense_75/bias:0', 'layer_normalization_26/gamma:0', 'layer_normalization_26/beta:0', 'dense_76/kernel:0', 'dense_76/bias:0', 'dense_77/kernel:0', 'dense_77/bias:0', 'layer_normalization_27/gamma:0', 'layer_normalization_27/beta:0', 'multi_head_attention_13/dense_78/kernel:0', 'multi_head_attention_13/dense_78/bias:0', 'multi_head_attention_13/dense_79/kernel:0', 'multi_head_attention_13/dense_79/bias:0', 'multi_head_attention_13/dense_80/kernel:0', 'multi_head_attention_13/dense_80/bias:0', 'multi_head_attention_13/dense_81/kernel:0', 'multi_head_attention_13/dense_81/bias:0', 'layer_normalization_28/gamma:0', 'layer_normalization_28/beta:0', 'dense_82/kernel:0', 'dense_82/bias:0', 'dense_83/kernel:0', 'dense_83/bias:0', 'layer_normalization_29/gamma:0', 'layer_normalization_29/beta:0', 'multi_head_attention_14/dense_84/kernel:0', 'multi_head_attention_14/dense_84/bias:0', 'multi_head_attention_14/dense_85/kernel:0', 'multi_head_attention_14/dense_85/bias:0', 'multi_head_attention_14/dense_86/kernel:0', 'multi_head_attention_14/dense_86/bias:0', 'multi_head_attention_14/dense_87/kernel:0', 'multi_head_attention_14/dense_87/bias:0', 'layer_normalization_30/gamma:0', 'layer_normalization_30/beta:0', 'dense_88/kernel:0', 'dense_88/bias:0', 'dense_89/kernel:0', 'dense_89/bias:0', 'layer_normalization_31/gamma:0', 'layer_normalization_31/beta:0', 'multi_head_attention_15/dense_90/kernel:0', 'multi_head_attention_15/dense_90/bias:0', 'multi_head_attention_15/dense_91/kernel:0', 'multi_head_attention_15/dense_91/bias:0', 'multi_head_attention_15/dense_92/kernel:0', 'multi_head_attention_15/dense_92/bias:0', 'multi_head_attention_15/dense_93/kernel:0', 'multi_head_attention_15/dense_93/bias:0', 'layer_normalization_32/gamma:0', 'layer_normalization_32/beta:0', 'dense_94/kernel:0', 'dense_94/bias:0', 'dense_95/kernel:0', 'dense_95/bias:0', 'layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'multi_head_attention_16/dense_96/kernel:0', 'multi_head_attention_16/dense_96/bias:0', 'multi_head_attention_16/dense_97/kernel:0', 'multi_head_attention_16/dense_97/bias:0', 'multi_head_attention_16/dense_98/kernel:0', 'multi_head_attention_16/dense_98/bias:0', 'multi_head_attention_16/dense_99/kernel:0', 'multi_head_attention_16/dense_99/bias:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'dense_100/kernel:0', 'dense_100/bias:0', 'dense_101/kernel:0', 'dense_101/bias:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'multi_head_attention_17/dense_102/kernel:0', 'multi_head_attention_17/dense_102/bias:0', 'multi_head_attention_17/dense_103/kernel:0', 'multi_head_attention_17/dense_103/bias:0', 'multi_head_attention_17/dense_104/kernel:0', 'multi_head_attention_17/dense_104/bias:0', 'multi_head_attention_17/dense_105/kernel:0', 'multi_head_attention_17/dense_105/bias:0', 'layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'dense_106/kernel:0', 'dense_106/bias:0', 'dense_107/kernel:0', 'dense_107/bias:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'multi_head_attention_18/dense_108/kernel:0', 'multi_head_attention_18/dense_108/bias:0', 'multi_head_attention_18/dense_109/kernel:0', 'multi_head_attention_18/dense_109/bias:0', 'multi_head_attention_18/dense_110/kernel:0', 'multi_head_attention_18/dense_110/bias:0', 'multi_head_attention_18/dense_111/kernel:0', 'multi_head_attention_18/dense_111/bias:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'dense_112/kernel:0', 'dense_112/bias:0', 'dense_113/kernel:0', 'dense_113/bias:0', 'layer_normalization_39/gamma:0', 'layer_normalization_39/beta:0', 'multi_head_attention_19/dense_114/kernel:0', 'multi_head_attention_19/dense_114/bias:0', 'multi_head_attention_19/dense_115/kernel:0', 'multi_head_attention_19/dense_115/bias:0', 'multi_head_attention_19/dense_116/kernel:0', 'multi_head_attention_19/dense_116/bias:0', 'multi_head_attention_19/dense_117/kernel:0', 'multi_head_attention_19/dense_117/bias:0', 'layer_normalization_40/gamma:0', 'layer_normalization_40/beta:0', 'dense_118/kernel:0', 'dense_118/bias:0', 'dense_119/kernel:0', 'dense_119/bias:0', 'layer_normalization_41/gamma:0', 'layer_normalization_41/beta:0', 'multi_head_attention_20/dense_120/kernel:0', 'multi_head_attention_20/dense_120/bias:0', 'multi_head_attention_20/dense_121/kernel:0', 'multi_head_attention_20/dense_121/bias:0', 'multi_head_attention_20/dense_122/kernel:0', 'multi_head_attention_20/dense_122/bias:0', 'multi_head_attention_20/dense_123/kernel:0', 'multi_head_attention_20/dense_123/bias:0', 'layer_normalization_42/gamma:0', 'layer_normalization_42/beta:0', 'dense_124/kernel:0', 'dense_124/bias:0', 'dense_125/kernel:0', 'dense_125/bias:0', 'layer_normalization_43/gamma:0', 'layer_normalization_43/beta:0', 'multi_head_attention_21/dense_126/kernel:0', 'multi_head_attention_21/dense_126/bias:0', 'multi_head_attention_21/dense_127/kernel:0', 'multi_head_attention_21/dense_127/bias:0', 'multi_head_attention_21/dense_128/kernel:0', 'multi_head_attention_21/dense_128/bias:0', 'multi_head_attention_21/dense_129/kernel:0', 'multi_head_attention_21/dense_129/bias:0', 'layer_normalization_44/gamma:0', 'layer_normalization_44/beta:0', 'dense_130/kernel:0', 'dense_130/bias:0', 'dense_131/kernel:0', 'dense_131/bias:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'multi_head_attention_22/dense_132/kernel:0', 'multi_head_attention_22/dense_132/bias:0', 'multi_head_attention_22/dense_133/kernel:0', 'multi_head_attention_22/dense_133/bias:0', 'multi_head_attention_22/dense_134/kernel:0', 'multi_head_attention_22/dense_134/bias:0', 'multi_head_attention_22/dense_135/kernel:0', 'multi_head_attention_22/dense_135/bias:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'dense_136/kernel:0', 'dense_136/bias:0', 'dense_137/kernel:0', 'dense_137/bias:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'multi_head_attention_23/dense_138/kernel:0', 'multi_head_attention_23/dense_138/bias:0', 'multi_head_attention_23/dense_139/kernel:0', 'multi_head_attention_23/dense_139/bias:0', 'multi_head_attention_23/dense_140/kernel:0', 'multi_head_attention_23/dense_140/bias:0', 'multi_head_attention_23/dense_141/kernel:0', 'multi_head_attention_23/dense_141/bias:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'dense_142/kernel:0', 'dense_142/bias:0', 'dense_143/kernel:0', 'dense_143/bias:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'pooler_layer_1/kernel:0', 'pooler_layer_1/bias:0', 'transform/bias:0', 'lm_layer_1/transform/dense/kernel:0', 'lm_layer_1/transform/dense/bias:0', 'lm_layer_1/transform/LayerNorm/gamma:0', 'lm_layer_1/transform/LayerNorm/beta:0', 'predictions/transform/logits_1/kernel:0', 'predictions/transform/logits_1/bias:0'].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-89147f218dcf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   1346\u001b[0m                                                     class_weight)\n\u001b[0;32m   1347\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    616\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2417\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2419\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2420\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2772\u001b[0m           \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2773\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[1;32m-> 2774\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2704\u001b[0m         relaxed_arg_shapes)\n\u001b[0;32m   2705\u001b[0m     graph_function = self._create_graph_function(\n\u001b[1;32m-> 2706\u001b[1;33m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[0;32m   2707\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2667\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2669\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 981\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    966\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\LGCNS\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    C:\\Users\\LGCNS\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\LGCNS\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\LGCNS\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\LGCNS\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:541 train_step  **\n        self.trainable_variables)\n    C:\\Users\\LGCNS\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1804 _minimize\n        trainable_variables))\n    C:\\Users\\LGCNS\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:521 _aggregate_gradients\n        filtered_grads_and_vars = _filter_grads(grads_and_vars)\n    C:\\Users\\LGCNS\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:1219 _filter_grads\n        ([v.name for _, v in grads_and_vars],))\n\n    ValueError: No gradients provided for any variable: ['embedding_2/embeddings:0', 'position_embedding_1/embeddings:0', 'embedding_3/embeddings:0', 'layer_normalization_25/gamma:0', 'layer_normalization_25/beta:0', 'multi_head_attention_12/dense_72/kernel:0', 'multi_head_attention_12/dense_72/bias:0', 'multi_head_attention_12/dense_73/kernel:0', 'multi_head_attention_12/dense_73/bias:0', 'multi_head_attention_12/dense_74/kernel:0', 'multi_head_attention_12/dense_74/bias:0', 'multi_head_attention_12/dense_75/kernel:0', 'multi_head_attention_12/dense_75/bias:0', 'layer_normalization_26/gamma:0', 'layer_normalization_26/beta:0', 'dense_76/kernel:0', 'dense_76/bias:0', 'dense_77/kernel:0', 'dense_77/bias:0', 'layer_normalization_27/gamma:0', 'layer_normalization_27/beta:0', 'multi_head_attention_13/dense_78/kernel:0', 'multi_head_attention_13/dense_78/bias:0', 'multi_head_attention_13/dense_79/kernel:0', 'multi_head_attention_13/dense_79/bias:0', 'multi_head_attention_13/dense_80/kernel:0', 'multi_head_attention_13/dense_80/bias:0', 'multi_head_attention_13/dense_81/kernel:0', 'multi_head_attention_13/dense_81/bias:0', 'layer_normalization_28/gamma:0', 'layer_normalization_28/beta:0', 'dense_82/kernel:0', 'dense_82/bias:0', 'dense_83/kernel:0', 'dense_83/bias:0', 'layer_normalization_29/gamma:0', 'layer_normalization_29/beta:0', 'multi_head_attention_14/dense_84/kernel:0', 'multi_head_attention_14/dense_84/bias:0', 'multi_head_attention_14/dense_85/kernel:0', 'multi_head_attention_14/dense_85/bias:0', 'multi_head_attention_14/dense_86/kernel:0', 'multi_head_attention_14/dense_86/bias:0', 'multi_head_attention_14/dense_87/kernel:0', 'multi_head_attention_14/dense_87/bias:0', 'layer_normalization_30/gamma:0', 'layer_normalization_30/beta:0', 'dense_88/kernel:0', 'dense_88/bias:0', 'dense_89/kernel:0', 'dense_89/bias:0', 'layer_normalization_31/gamma:0', 'layer_normalization_31/beta:0', 'multi_head_attention_15/dense_90/kernel:0', 'multi_head_attention_15/dense_90/bias:0', 'multi_head_attention_15/dense_91/kernel:0', 'multi_head_attention_15/dense_91/bias:0', 'multi_head_attention_15/dense_92/kernel:0', 'multi_head_attention_15/dense_92/bias:0', 'multi_head_attention_15/dense_93/kernel:0', 'multi_head_attention_15/dense_93/bias:0', 'layer_normalization_32/gamma:0', 'layer_normalization_32/beta:0', 'dense_94/kernel:0', 'dense_94/bias:0', 'dense_95/kernel:0', 'dense_95/bias:0', 'layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'multi_head_attention_16/dense_96/kernel:0', 'multi_head_attention_16/dense_96/bias:0', 'multi_head_attention_16/dense_97/kernel:0', 'multi_head_attention_16/dense_97/bias:0', 'multi_head_attention_16/dense_98/kernel:0', 'multi_head_attention_16/dense_98/bias:0', 'multi_head_attention_16/dense_99/kernel:0', 'multi_head_attention_16/dense_99/bias:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'dense_100/kernel:0', 'dense_100/bias:0', 'dense_101/kernel:0', 'dense_101/bias:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'multi_head_attention_17/dense_102/kernel:0', 'multi_head_attention_17/dense_102/bias:0', 'multi_head_attention_17/dense_103/kernel:0', 'multi_head_attention_17/dense_103/bias:0', 'multi_head_attention_17/dense_104/kernel:0', 'multi_head_attention_17/dense_104/bias:0', 'multi_head_attention_17/dense_105/kernel:0', 'multi_head_attention_17/dense_105/bias:0', 'layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'dense_106/kernel:0', 'dense_106/bias:0', 'dense_107/kernel:0', 'dense_107/bias:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'multi_head_attention_18/dense_108/kernel:0', 'multi_head_attention_18/dense_108/bias:0', 'multi_head_attention_18/dense_109/kernel:0', 'multi_head_attention_18/dense_109/bias:0', 'multi_head_attention_18/dense_110/kernel:0', 'multi_head_attention_18/dense_110/bias:0', 'multi_head_attention_18/dense_111/kernel:0', 'multi_head_attention_18/dense_111/bias:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'dense_112/kernel:0', 'dense_112/bias:0', 'dense_113/kernel:0', 'dense_113/bias:0', 'layer_normalization_39/gamma:0', 'layer_normalization_39/beta:0', 'multi_head_attention_19/dense_114/kernel:0', 'multi_head_attention_19/dense_114/bias:0', 'multi_head_attention_19/dense_115/kernel:0', 'multi_head_attention_19/dense_115/bias:0', 'multi_head_attention_19/dense_116/kernel:0', 'multi_head_attention_19/dense_116/bias:0', 'multi_head_attention_19/dense_117/kernel:0', 'multi_head_attention_19/dense_117/bias:0', 'layer_normalization_40/gamma:0', 'layer_normalization_40/beta:0', 'dense_118/kernel:0', 'dense_118/bias:0', 'dense_119/kernel:0', 'dense_119/bias:0', 'layer_normalization_41/gamma:0', 'layer_normalization_41/beta:0', 'multi_head_attention_20/dense_120/kernel:0', 'multi_head_attention_20/dense_120/bias:0', 'multi_head_attention_20/dense_121/kernel:0', 'multi_head_attention_20/dense_121/bias:0', 'multi_head_attention_20/dense_122/kernel:0', 'multi_head_attention_20/dense_122/bias:0', 'multi_head_attention_20/dense_123/kernel:0', 'multi_head_attention_20/dense_123/bias:0', 'layer_normalization_42/gamma:0', 'layer_normalization_42/beta:0', 'dense_124/kernel:0', 'dense_124/bias:0', 'dense_125/kernel:0', 'dense_125/bias:0', 'layer_normalization_43/gamma:0', 'layer_normalization_43/beta:0', 'multi_head_attention_21/dense_126/kernel:0', 'multi_head_attention_21/dense_126/bias:0', 'multi_head_attention_21/dense_127/kernel:0', 'multi_head_attention_21/dense_127/bias:0', 'multi_head_attention_21/dense_128/kernel:0', 'multi_head_attention_21/dense_128/bias:0', 'multi_head_attention_21/dense_129/kernel:0', 'multi_head_attention_21/dense_129/bias:0', 'layer_normalization_44/gamma:0', 'layer_normalization_44/beta:0', 'dense_130/kernel:0', 'dense_130/bias:0', 'dense_131/kernel:0', 'dense_131/bias:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'multi_head_attention_22/dense_132/kernel:0', 'multi_head_attention_22/dense_132/bias:0', 'multi_head_attention_22/dense_133/kernel:0', 'multi_head_attention_22/dense_133/bias:0', 'multi_head_attention_22/dense_134/kernel:0', 'multi_head_attention_22/dense_134/bias:0', 'multi_head_attention_22/dense_135/kernel:0', 'multi_head_attention_22/dense_135/bias:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'dense_136/kernel:0', 'dense_136/bias:0', 'dense_137/kernel:0', 'dense_137/bias:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'multi_head_attention_23/dense_138/kernel:0', 'multi_head_attention_23/dense_138/bias:0', 'multi_head_attention_23/dense_139/kernel:0', 'multi_head_attention_23/dense_139/bias:0', 'multi_head_attention_23/dense_140/kernel:0', 'multi_head_attention_23/dense_140/bias:0', 'multi_head_attention_23/dense_141/kernel:0', 'multi_head_attention_23/dense_141/bias:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'dense_142/kernel:0', 'dense_142/bias:0', 'dense_143/kernel:0', 'dense_143/bias:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'pooler_layer_1/kernel:0', 'pooler_layer_1/bias:0', 'transform/bias:0', 'lm_layer_1/transform/dense/kernel:0', 'lm_layer_1/transform/dense/bias:0', 'lm_layer_1/transform/LayerNorm/gamma:0', 'lm_layer_1/transform/LayerNorm/beta:0', 'predictions/transform/logits_1/kernel:0', 'predictions/transform/logits_1/bias:0'].\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
