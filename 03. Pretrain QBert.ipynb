{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from QBert.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from copy import deepcopy\n",
    "\n",
    "import import_ipynb\n",
    "from QBert import qbert_model\n",
    "\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def load_pkl(file_path) :\n",
    "    \n",
    "    with open(file_path, 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def save_pkl(df, file_path) :\n",
    "    \n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(df, f)\n",
    "\n",
    "def create_padding_mask(x):\n",
    "    init_shape = x.shape\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, key의 문장 길이)\n",
    "    return np.array(mask).reshape(init_shape[0], 1,1, init_shape[1])\n",
    "\n",
    "def ind_to_weight(masked_pos, seq_len) :\n",
    "    return tf.reduce_sum(tf.one_hot(masked_pos, seq_len), axis = 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertModule(tf.keras.Model) :\n",
    "\n",
    "    def __init__(self, vocab_size, max_seq_len, num_layers, dff, d_model, num_heads, dropout, name) :\n",
    "        super(BertModule, self).__init__()\n",
    "        self.Bert = qbert_model(vocab_size, max_seq_len, num_layers, dff, d_model, num_heads, dropout, name)\n",
    "        self.dense_cls = tf.keras.layers.Dense(2, activation = 'softmax', use_bias = False)\n",
    "        self.vocab_size = vocab_size\n",
    "    \n",
    "    def call(self, inputs) :\n",
    "        \n",
    "        x, mask, lm, nsp, weight = inputs[0], inputs[1], inputs[2], inputs[3], inputs[4]\n",
    "    \n",
    "        bert_outputs = self.Bert([x, mask])\n",
    "\n",
    "        y_pred = bert_outputs['sequence_output']\n",
    "\n",
    "        decode_matrix = tf.linalg.pinv(self.Bert.layers[1].weights[0])\n",
    "\n",
    "        pred_lm =  tf.math.softmax(tf.matmul(y_pred, decode_matrix))\n",
    "        pred_cls = self.dense_cls(y_pred[:, 0])\n",
    "\n",
    "        true_y_lm = tf.cast(tf.one_hot(tf.cast(lm, dtype = tf.int32), depth = self.vocab_size), dtype = tf.float32)\n",
    "\n",
    "        lm_losses = (tf.reduce_sum(true_y_lm * -tf.math.log(pred_lm), axis = 2))\n",
    "        lm_losses = tf.reduce_mean(lm_losses * weight, axis = 1)\n",
    "        \n",
    "        nsp = tf.cast(nsp, dtype = tf.float32)\n",
    "        cls_losses = tf.reduce_mean(tf.reduce_sum(nsp * -tf.math.log(pred_cls), axis = 1))\n",
    "\n",
    "        total_loss = lm_losses + cls_losses\n",
    "\n",
    "        return total_loss\n",
    "    \n",
    "    def get_pretrained_result(self, inputs) :\n",
    "        \n",
    "        x, mask = inputs[0], inputs[1]\n",
    "    \n",
    "        bert_outputs = self.Bert([x, mask])\n",
    "\n",
    "        y_pred = bert_outputs['sequence_output']\n",
    "\n",
    "        decode_matrix = tf.linalg.pinv(self.Bert.layers[1].weights[0])\n",
    "\n",
    "        pred_lm =  tf.math.softmax(tf.matmul(y_pred, decode_matrix))\n",
    "        pred_cls = self.dense_cls(y_pred[:, 0])\n",
    "        \n",
    "        return pred_lm, pred_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_BertModule(vocab_size, max_seq_len, num_layers, dff, d_model, num_heads, dropout, name) :\n",
    "    \n",
    "    x = tf.keras.Input(shape = (None, ), name = 'MASKED_X_INPUT')\n",
    "    mask = tf.keras.Input(shape = (1, 1, None), name = 'MASKING_INPUT')\n",
    "    lm = tf.keras.Input(shape = (None, ), name = 'WORD_LABEING_INPUT')\n",
    "    nsp = tf.keras.Input(shape = (None, ), name = 'NEXT_SENTENCE_PREDICTION_INPUT')\n",
    "    weight = tf.keras.Input(shape = (None, ), name = 'MASKING_WEIGHT')\n",
    "    \n",
    "    \n",
    "    Bert = qbert_model(vocab_size, max_seq_len, num_layers, dff, d_model, num_heads, dropout, name)\n",
    "    dense_cls = tf.keras.layers.Dense(2, activation = 'softmax', use_bias = False)\n",
    "\n",
    "    bert_outputs = Bert([x, mask])\n",
    "\n",
    "    y_pred = bert_outputs['sequence_output']\n",
    "\n",
    "    decode_matrix = tf.linalg.pinv(Bert.layers[1].weights[0])\n",
    "\n",
    "    pred_lm =  tf.math.softmax(tf.matmul(y_pred, decode_matrix))\n",
    "    pred_cls = dense_cls(y_pred[:, 0])\n",
    "\n",
    "    true_y_lm = tf.cast(tf.one_hot(tf.cast(lm, dtype = tf.int32), depth = vocab_size), dtype = tf.float32)\n",
    "\n",
    "    lm_losses = (tf.reduce_sum(true_y_lm * -tf.math.log(pred_lm), axis = 2))\n",
    "    lm_losses = tf.reduce_mean(lm_losses * weight, axis = 1)\n",
    "    \n",
    "    nsp = tf.cast(nsp, dtype = tf.float32)\n",
    "    \n",
    "    cls_losses = tf.reduce_mean(tf.reduce_sum(nsp * -tf.math.log(pred_cls), axis = 1))\n",
    "    \n",
    "    total_loss = lm_losses + cls_losses\n",
    "    \n",
    "    return tf.keras.Model(inputs = [x, mask, lm, nsp, weight], outputs = total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = load_pkl('./dt/train_set_under_255.pkl')\n",
    "train = load_pkl('./dt/train_set-maksed-position-sample-10000.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = list(filter(lambda x: len(x['x']) <= 130, train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 32000\n",
    "max_seq_len = 130\n",
    "num_layers = 3\n",
    "dff = 256\n",
    "d_model = 100\n",
    "num_heads = 5\n",
    "dropout = .1\n",
    "name = 'qbert_210603'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "\n",
    "x = pad_sequences([ x['x'] for x in train ], max_seq_len, padding = 'post')\n",
    "y = pad_sequences([ x['label'] for x in train ] , max_seq_len, padding = 'post')\n",
    "nsp = np.asarray([ x['NSP'] for x in train ])\n",
    "\n",
    "masked_lm_weight = np.array([ ind_to_weight(x['masked_position'], max_seq_len) for x in train])\n",
    "\n",
    "mask = create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "lr = 1e-3\n",
    "batch_size = 5\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrainBert = BertModule(vocab_size, max_seq_len, num_layers, dff, d_model, num_heads, dropout, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.9267648 , 0.76721823], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrainBert([x[0:2], mask[0:2], y[0:2], nsp[0:2], masked_lm_weight[0:2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrainBert.compile(optimizer=optimizer, loss ='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_y = np.array([ 0 for _ in range(len(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_25/kernel:0', 'dense_25/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_25/kernel:0', 'dense_25/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LGCNS\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_25/kernel:0', 'dense_25/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_25/kernel:0', 'dense_25/bias:0'] when minimizing the loss.\n",
      " 150/1982 [=>............................] - ETA: 32:38 - loss: 2.0790"
     ]
    }
   ],
   "source": [
    "hist = pretrainBert.fit(batch_size = batch_size, epochs = epochs\n",
    "                        , x = [x, mask, y, nsp, masked_lm_weight[:]], y = false_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/BertPretrained-210603-130-3-100-5.pt\\assets\n"
     ]
    }
   ],
   "source": [
    "today = '210603'\n",
    "\n",
    "pretrainBert.save('./model/BertPretrained-{}-{}-{}-{}-{}.pt'.format(today, max_seq_len, num_layers, d_model, num_heads))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train_set = train[np.random.randint(0, len(train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = load_pkl('./dt/train_set_under_255.pkl')[np.random.randint(10000, 1000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling BertTokenizerFast.from_pretrained() with the path to a single file or url is deprecated\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "\n",
    "tokenizer_for_load = BertTokenizerFast.from_pretrained('./model/BertTokenizer-6000-32000-vocab.txt'\n",
    "                                                   , strip_accents=False\n",
    "                                                   , lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] [MASK] 속 ##성이 유지 [MASK] 물질의 가장 정밀 ##한 부분은 미 ##립 [MASK] 수준에 있다고 논 ##평 ##했다 . [SEP] 그는 또한 공기 펌 ##프로 수 많은 조사를 수행 ##했으며 , 공기 ##가 펌 184 퍼져 나 ##감에 따라 수은 ##이 떨어지는 것으로 나타났다 . [SEP]'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_statement = ' '.join(tokenizer_for_load.convert_ids_to_tokens(sample_train_set['x']))\n",
    "train_statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 그는 속 ##성이 유지 ##되는 물질의 가장 정밀 ##한 부분은 미 ##립 ##자의 수준에 있다고 논 ##평 ##했다 . [SEP] 그는 또한 공기 펌 ##프로 수 많은 조사를 수행 ##했으며 , 공기 ##가 펌 ##프로 퍼져 나 ##감에 따라 수은 ##이 떨어지는 것으로 나타났다 . [SEP]'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_statement = ' '.join(tokenizer_for_load.convert_ids_to_tokens(sample_train_set['label']))\n",
    "train_statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train_set = train[np.random.randint(0, len(train))]\n",
    "\n",
    "train_x = tf.reshape(sample_train_set['x'], (1, -1))\n",
    "train_x = pad_sequences(train_x, max_seq_len, padding = 'post')\n",
    "mask = create_padding_mask(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm, nls = pretrainBert.get_pretrained_result([train_x, mask, \"\", \"\", \"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8565"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_for_load.convert_tokens_to_ids(\"그는\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.7333563e-05>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.019898778>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm[0][0][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.9875746e-05>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm[0][0][8565]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(lm[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_for_load.convert_ids_to_tokens([15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 130), dtype=int64, numpy=\n",
       "array([[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        15, 15]], dtype=int64)>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(lm, axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.45470825, 0.5452918 ]], dtype=float32)>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'embedding_19/embeddings:0' shape=(32000, 100) dtype=float32, numpy=\n",
       "array([[ 0.00675264,  0.02614969,  0.04783888, ...,  0.00074808,\n",
       "         0.0081974 ,  0.02426926],\n",
       "       [ 0.02625655,  0.00214106,  0.02599093, ..., -0.0249519 ,\n",
       "        -0.02679936,  0.01629817],\n",
       "       [ 0.00712447, -0.02990005,  0.02621973, ..., -0.00580653,\n",
       "        -0.00704775,  0.00537025],\n",
       "       ...,\n",
       "       [-0.0472474 ,  0.00386853, -0.00768339, ...,  0.02705099,\n",
       "        -0.03506238,  0.0258582 ],\n",
       "       [-0.00262028,  0.02314945,  0.00940512, ...,  0.02038808,\n",
       "         0.02099202, -0.02432241],\n",
       "       [ 0.02712569, -0.00255732, -0.04550922, ..., -0.00697222,\n",
       "        -0.04350788,  0.0189664 ]], dtype=float32)>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrainBert.Bert.layers[1].weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
