{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"colab":{"name":"03. Pretrain QBert.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wgJrLLaHrEn0","executionInfo":{"status":"ok","timestamp":1622714068749,"user_tz":-540,"elapsed":5363,"user":{"displayName":"NAVY_LIGHTS Q","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6Piv3pw8kuU3FwG96XJr1Utla0LhE59_h-rbnBQ=s64","userId":"05414969994838022364"}},"outputId":"22ddf6ac-4960-423d-fdfe-a2429d8c6171"},"source":["!pip install import_ipynb\n","\n","!pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: import_ipynb in /usr/local/lib/python3.7/dist-packages (0.1.3)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (3.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1rc1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.95)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"K2sd8cOErEdF","executionInfo":{"status":"ok","timestamp":1622714086233,"user_tz":-540,"elapsed":246,"user":{"displayName":"NAVY_LIGHTS Q","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6Piv3pw8kuU3FwG96XJr1Utla0LhE59_h-rbnBQ=s64","userId":"05414969994838022364"}}},"source":["import os\n","from google.colab import drive"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aR2a6kUgrD8-","executionInfo":{"status":"ok","timestamp":1622706931466,"user_tz":-540,"elapsed":19,"user":{"displayName":"NAVY_LIGHTS Q","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6Piv3pw8kuU3FwG96XJr1Utla0LhE59_h-rbnBQ=s64","userId":"05414969994838022364"}},"outputId":"5315face-ad32-457f-e6ae-2878b683b881"},"source":["drive.mount('/content/qdrive')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/qdrive; to attempt to forcibly remount, call drive.mount(\"/content/qdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"43c3viRbrWB_","executionInfo":{"status":"ok","timestamp":1622714087356,"user_tz":-540,"elapsed":13,"user":{"displayName":"NAVY_LIGHTS Q","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6Piv3pw8kuU3FwG96XJr1Utla0LhE59_h-rbnBQ=s64","userId":"05414969994838022364"}}},"source":["os.chdir('/content/qdrive/MyDrive/Colab Notebooks/QBert')"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fvNjNUbUrCa4","executionInfo":{"status":"ok","timestamp":1622714089490,"user_tz":-540,"elapsed":568,"user":{"displayName":"NAVY_LIGHTS Q","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6Piv3pw8kuU3FwG96XJr1Utla0LhE59_h-rbnBQ=s64","userId":"05414969994838022364"}},"outputId":"a4e2564a-d9c2-4f02-cb5c-037b94d7dff3"},"source":["import numpy as np\n","import tensorflow as tf\n","from copy import deepcopy\n","\n","import import_ipynb\n","from QBert import qbert_model\n","\n","import pickle\n","from tqdm.notebook import tqdm\n","\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","def load_pkl(file_path) :\n","    \n","    with open(file_path, 'rb') as f:\n","        df = pickle.load(f)\n","        \n","    return df\n","\n","def save_pkl(df, file_path) :\n","    \n","    with open(file_path, 'wb') as f:\n","        pickle.dump(df, f)\n","\n","def create_padding_mask(x):\n","    init_shape = x.shape\n","    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n","    # (batch_size, 1, 1, key의 문장 길이)\n","    return np.array(mask).reshape(init_shape[0], 1,1, init_shape[1])\n","\n","def ind_to_weight(masked_pos, seq_len) :\n","    return tf.reduce_sum(tf.one_hot(masked_pos, seq_len), axis = 0)\n","\n","def create_segments(inputs) :\n","    \n","    segment = []\n","    segment_num = 0\n","    \n","    for i, x in enumerate(inputs) :\n","        \n","        segment.append(segment_num)\n","        \n","        if x == 3 :\n","            segment_num+=1\n","            \n","    return np.array(segment)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["importing Jupyter notebook from QBert.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N9YHSgmGrCa-","executionInfo":{"status":"ok","timestamp":1622714092393,"user_tz":-540,"elapsed":371,"user":{"displayName":"NAVY_LIGHTS Q","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6Piv3pw8kuU3FwG96XJr1Utla0LhE59_h-rbnBQ=s64","userId":"05414969994838022364"}}},"source":["class BertModule(tf.keras.Model) :\n","\n","    def __init__(self, vocab_size, max_seq_len, num_layers, dff, d_model, num_heads, dropout, name) :\n","        super(BertModule, self).__init__()\n","        self.Bert = qbert_model(vocab_size, max_seq_len, num_layers, dff, d_model, num_heads, dropout, name)\n","        self.dense_cls = tf.keras.layers.Dense(2, activation = 'softmax', use_bias = False)\n","        self.vocab_size = vocab_size\n","    \n","    def call(self, inputs) :\n","        \n","        x, mask, lm, nsp, weight, segments = inputs[0], inputs[1], inputs[2], inputs[3], inputs[4], inputs[5]\n","    \n","        bert_outputs = self.Bert([x, mask, segments])\n","\n","        y_pred = bert_outputs['sequence_output']\n","\n","        decode_matrix = tf.linalg.pinv(self.Bert.layers[1].weights[0])\n","\n","        pred_lm =  tf.math.softmax(tf.matmul(y_pred, decode_matrix))\n","        pred_cls = self.dense_cls(y_pred[:, 0])\n","\n","        true_y_lm = tf.cast(tf.one_hot(tf.cast(lm, dtype = tf.int32), depth = self.vocab_size), dtype = tf.float32)\n","\n","        lm_losses = (tf.reduce_sum(true_y_lm * -tf.math.log(pred_lm), axis = 2))\n","        lm_losses = lm_losses * weight\n","        lm_losses = tf.reduce_mean(lm_losses, axis = 1)\n","\n","        nsp = tf.cast(nsp, dtype = tf.float32)\n","        cls_losses = tf.reduce_mean(tf.reduce_sum(nsp * -tf.math.log(pred_cls), axis = 1))\n","\n","        total_loss = lm_losses + cls_losses\n","\n","        return total_loss\n","    \n","    def get_pretrained_result(self, inputs) :\n","        \n","        x, mask = inputs[0], inputs[1]\n","    \n","        bert_outputs = self.Bert([x, mask])\n","\n","        y_pred = bert_outputs['sequence_output']\n","\n","        decode_matrix = tf.linalg.pinv(self.Bert.layers[1].weights[0])\n","\n","        pred_lm =  tf.math.softmax(tf.matmul(y_pred, decode_matrix))\n","        pred_cls = self.dense_cls(y_pred[:, 0])\n","        \n","        return pred_lm, pred_cls"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"DWQKdef2JfG4","executionInfo":{"status":"ok","timestamp":1622714093657,"user_tz":-540,"elapsed":243,"user":{"displayName":"NAVY_LIGHTS Q","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6Piv3pw8kuU3FwG96XJr1Utla0LhE59_h-rbnBQ=s64","userId":"05414969994838022364"}}},"source":["def process_inputs(train, max_seq_len) :\n","    \n","    train = list(filter(lambda x: len(x['x']) <= max_seq_len, train))\n","\n","    x = pad_sequences([ inputs['x'] for inputs in train ], max_seq_len, padding = 'post')\n","    y = pad_sequences([ inputs['label'] for inputs in train ] , max_seq_len, padding = 'post')\n","    nsp = np.asarray([ inputs['NSP'] for inputs in train ])\n","\n","    weight = np.array([ ind_to_weight(inputs['masked_position'], max_seq_len) for inputs in train])\n","    segments = np.array([ create_segments(inputs) for inputs in x])\n","\n","    mask = create_padding_mask(x)\n","\n","    return x, y, nsp, weight, segments, mask"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"rFnnCKzErCbC","executionInfo":{"status":"ok","timestamp":1622714094570,"user_tz":-540,"elapsed":6,"user":{"displayName":"NAVY_LIGHTS Q","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6Piv3pw8kuU3FwG96XJr1Utla0LhE59_h-rbnBQ=s64","userId":"05414969994838022364"}}},"source":["vocab_size = 32000\n","max_seq_len = 130\n","num_layers = 3\n","dff = 256\n","d_model = 100\n","num_heads = 5\n","dropout = .1\n","name = 'qbert_210603'"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"kfE1RvqwNckW","executionInfo":{"status":"ok","timestamp":1622714095422,"user_tz":-540,"elapsed":11,"user":{"displayName":"NAVY_LIGHTS Q","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6Piv3pw8kuU3FwG96XJr1Utla0LhE59_h-rbnBQ=s64","userId":"05414969994838022364"}}},"source":["data_path = '/content/qdrive/MyDrive/Data_Backup/210601_Bert_DT_BU/dt/'\n","\n","ds_set = list(filter(lambda x : x.startswith('train_set-masked-position-'), os.listdir(data_path)))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"U2RzFd6HOmnm","executionInfo":{"status":"ok","timestamp":1622714096889,"user_tz":-540,"elapsed":244,"user":{"displayName":"NAVY_LIGHTS Q","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6Piv3pw8kuU3FwG96XJr1Utla0LhE59_h-rbnBQ=s64","userId":"05414969994838022364"}}},"source":["epochs = 1\n","lr = 1e-4\n","batch_size = 128"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"s5XRgPNwOpRo","executionInfo":{"status":"ok","timestamp":1622714103816,"user_tz":-540,"elapsed":6008,"user":{"displayName":"NAVY_LIGHTS Q","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6Piv3pw8kuU3FwG96XJr1Utla0LhE59_h-rbnBQ=s64","userId":"05414969994838022364"}}},"source":["pretrainBert = BertModule(vocab_size, max_seq_len, num_layers, dff, d_model, num_heads, dropout, name)\n","\n","optimizer = tf.keras.optimizers.Adam(lr, beta_1=0.9, beta_2=0.999)\n","pretrainBert.compile(optimizer=optimizer, loss ='mse')"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"XaaLv3CmPVRp","executionInfo":{"status":"ok","timestamp":1622714103817,"user_tz":-540,"elapsed":29,"user":{"displayName":"NAVY_LIGHTS Q","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6Piv3pw8kuU3FwG96XJr1Utla0LhE59_h-rbnBQ=s64","userId":"05414969994838022364"}}},"source":["from datetime import datetime"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"lhYKc4n7T4Qr","executionInfo":{"status":"ok","timestamp":1622714326024,"user_tz":-540,"elapsed":222,"user":{"displayName":"NAVY_LIGHTS Q","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6Piv3pw8kuU3FwG96XJr1Utla0LhE59_h-rbnBQ=s64","userId":"05414969994838022364"}}},"source":["import math"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T22818KXN9I_","outputId":"5aae77ce-b6e1-4d1d-e2cc-ab347560f82c"},"source":["losses = []\n","\n","for epoch in range(epochs) :\n","\n","    total_step = 0\n","    now = datetime.now()\n","    print(\"EPOCH {} START ON {}\".format(epoch, now))\n","\n","    optimizer = tf.keras.optimizers.Adam(lr, beta_1=0.9, beta_2=0.999)\n","    pretrainBert.compile(optimizer=optimizer, loss ='mse')\n","\n","    for ds in ds_set[0:1] :\n","\n","        print(\"TRAIN ON {}\".format(ds))\n","        dataset = load_pkl(os.path.join(data_path, ds))\n","        print(\"Data Loaded..\")\n","        # x, y, nsp, weight, segments, mask = process_inputs(dataset, max_seq_len)\n","        print(\"Data Processed\")\n","        print(\"Start Training on {}\".format(ds))\n","        \n","        steps = math.ceil(len(x) / batch_size)\n","\n","        for idx in range(steps) :\n","\n","            batch_x = x[idx * batch_size: (idx+1)*batch_size]\n","            batch_y = y[idx * batch_size: (idx+1)*batch_size]\n","            batch_mask = mask[idx * batch_size: (idx+1)*batch_size]\n","            batch_nsp = nsp[idx * batch_size: (idx+1)*batch_size]\n","            batch_weight = weight[idx * batch_size: (idx+1)*batch_size]\n","            batch_segments = segments[idx * batch_size: (idx+1)*batch_size]\n","            false_y = np.array([ 0 for _ in range(batch_size)])\n","\n","            loss = pretrainBert.train_on_batch(x = [batch_x, batch_mask, batch_y, batch_nsp, batch_weight, batch_segments]\n","                                               , y = false_y)\n","            losses.append(loss)\n","\n","            if (idx % 500 == 0) | (idx+1) == steps) :\n","                print(\"Training -- {}/{} step -- {}\".format(idx, steps+1, losses[-1]))\n","\n","            total_step += 1\n","\n","        print(\"Trained on {}_Loss {}\".format(ds, losses[-1]))\n","\n","        del([batch_x, batch_y, batch_mask, batch_nsp, batch_weight, batch_segments])\n","        del([dataset, x, y, nsp, weight, segments, mask, false_y])\n","    \n","    print(\"EPOCH {} END ON {} ({} 소요) \".format(epoch, datetime.now(), datetime.now() - now))\n","\n","    pretrainBert.save_weights('/content/qdrive/MyDrive/Data_Backup/210601_Bert_DT_BU/model_weight_2106031849-epoch-{}-loss-{:.3f}.tf'.format(epoch, losses[-1]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["EPOCH 0 START ON 2021-06-03 09:59:59.259551\n","TRAIN ON train_set-masked-position-0.pkl\n","Data Loaded..\n","Data Processed\n","Start Training on train_set-masked-position-0.pkl\n","Training -- 1/2318 step -- 2.3771562576293945\n","Training -- 11/2318 step -- 3.0186190605163574\n","Training -- 21/2318 step -- 1.7656855583190918\n","Training -- 31/2318 step -- 2.1527233123779297\n","Training -- 41/2318 step -- 2.0238115787506104\n","Training -- 51/2318 step -- 1.857027530670166\n","Training -- 61/2318 step -- 1.5402508974075317\n","Training -- 71/2318 step -- 2.060739040374756\n","Training -- 81/2318 step -- 2.029837131500244\n","Training -- 91/2318 step -- 2.3308801651000977\n","Training -- 101/2318 step -- 1.7787905931472778\n","Training -- 111/2318 step -- 1.7355079650878906\n","Training -- 121/2318 step -- 1.855301856994629\n","Training -- 131/2318 step -- 2.0016918182373047\n","Training -- 141/2318 step -- 1.7667165994644165\n","Training -- 151/2318 step -- 1.9967494010925293\n","Training -- 161/2318 step -- 1.8256560564041138\n","Training -- 171/2318 step -- 1.9883991479873657\n","Training -- 181/2318 step -- 1.9830780029296875\n","Training -- 191/2318 step -- 1.6651699542999268\n","Training -- 201/2318 step -- 1.7738261222839355\n","Training -- 211/2318 step -- 2.2169671058654785\n","Training -- 221/2318 step -- 1.7730860710144043\n","Training -- 231/2318 step -- 1.6859767436981201\n","Training -- 241/2318 step -- 1.7159769535064697\n","Training -- 251/2318 step -- 1.6995227336883545\n","Training -- 261/2318 step -- 1.6510450839996338\n","Training -- 271/2318 step -- 1.6750907897949219\n","Training -- 281/2318 step -- 1.9668501615524292\n","Training -- 291/2318 step -- 2.029229164123535\n","Training -- 301/2318 step -- 1.906982183456421\n","Training -- 311/2318 step -- 1.8510605096817017\n","Training -- 321/2318 step -- 2.190009593963623\n","Training -- 331/2318 step -- 1.8949990272521973\n","Training -- 341/2318 step -- 2.040188789367676\n","Training -- 351/2318 step -- 1.7064605951309204\n","Training -- 361/2318 step -- 2.076936721801758\n","Training -- 371/2318 step -- 1.6579551696777344\n","Training -- 381/2318 step -- 1.8022456169128418\n","Training -- 391/2318 step -- 2.157515287399292\n","Training -- 401/2318 step -- 1.7530781030654907\n","Training -- 411/2318 step -- 1.6204349994659424\n","Training -- 421/2318 step -- 1.9728028774261475\n","Training -- 431/2318 step -- 1.8229882717132568\n","Training -- 441/2318 step -- 1.8601963520050049\n","Training -- 451/2318 step -- 1.7650127410888672\n","Training -- 461/2318 step -- 1.919610619544983\n","Training -- 471/2318 step -- 1.8894283771514893\n","Training -- 481/2318 step -- 1.8689181804656982\n","Training -- 491/2318 step -- 1.9655983448028564\n","Training -- 501/2318 step -- 1.332114338874817\n","Training -- 511/2318 step -- 1.891843318939209\n","Training -- 521/2318 step -- 1.8384979963302612\n","Training -- 531/2318 step -- 1.7581870555877686\n","Training -- 541/2318 step -- 2.010240077972412\n","Training -- 551/2318 step -- 1.6161344051361084\n","Training -- 561/2318 step -- 1.987858533859253\n","Training -- 571/2318 step -- 1.73025643825531\n","Training -- 581/2318 step -- 2.0406851768493652\n","Training -- 591/2318 step -- 1.7148563861846924\n","Training -- 601/2318 step -- 1.7234528064727783\n","Training -- 611/2318 step -- 1.8405160903930664\n","Training -- 621/2318 step -- 1.8448516130447388\n","Training -- 631/2318 step -- 1.790037989616394\n","Training -- 641/2318 step -- 1.8327966928482056\n","Training -- 651/2318 step -- 2.0250959396362305\n","Training -- 661/2318 step -- 1.8682949542999268\n","Training -- 671/2318 step -- 1.7661329507827759\n","Training -- 681/2318 step -- 1.5129956007003784\n","Training -- 691/2318 step -- 1.6921802759170532\n","Training -- 701/2318 step -- 1.6909366846084595\n","Training -- 711/2318 step -- 1.6820638179779053\n","Training -- 721/2318 step -- 1.5134634971618652\n","Training -- 731/2318 step -- 2.021528482437134\n","Training -- 741/2318 step -- 1.78583824634552\n","Training -- 751/2318 step -- 1.8970146179199219\n","Training -- 761/2318 step -- 1.5927315950393677\n","Training -- 771/2318 step -- 1.7900996208190918\n","Training -- 781/2318 step -- 1.413508653640747\n","Training -- 791/2318 step -- 1.8271193504333496\n","Training -- 801/2318 step -- 1.7579588890075684\n","Training -- 811/2318 step -- 1.5788121223449707\n","Training -- 821/2318 step -- 1.7641329765319824\n","Training -- 831/2318 step -- 1.7215101718902588\n","Training -- 841/2318 step -- 1.797222375869751\n","Training -- 851/2318 step -- 2.14387583732605\n","Training -- 861/2318 step -- 1.8082599639892578\n","Training -- 871/2318 step -- 1.5927807092666626\n","Training -- 881/2318 step -- 1.2709054946899414\n","Training -- 891/2318 step -- 1.4168806076049805\n","Training -- 901/2318 step -- 2.1010966300964355\n","Training -- 911/2318 step -- 2.0842957496643066\n","Training -- 921/2318 step -- 1.806808352470398\n","Training -- 931/2318 step -- 1.6297730207443237\n","Training -- 941/2318 step -- 1.4217230081558228\n","Training -- 951/2318 step -- 1.8498873710632324\n","Training -- 961/2318 step -- 1.8257503509521484\n","Training -- 971/2318 step -- 1.2588855028152466\n","Training -- 981/2318 step -- 1.8408960103988647\n","Training -- 991/2318 step -- 1.8315141201019287\n","Training -- 1001/2318 step -- 1.9940491914749146\n","Training -- 1011/2318 step -- 1.858944058418274\n","Training -- 1021/2318 step -- 1.215192198753357\n","Training -- 1031/2318 step -- 1.690699815750122\n","Training -- 1041/2318 step -- 1.8796517848968506\n","Training -- 1051/2318 step -- 1.334822177886963\n","Training -- 1061/2318 step -- 1.539139986038208\n","Training -- 1071/2318 step -- 1.342003583908081\n","Training -- 1081/2318 step -- 1.3321810960769653\n","Training -- 1091/2318 step -- 1.5515609979629517\n","Training -- 1101/2318 step -- 1.5404140949249268\n","Training -- 1111/2318 step -- 1.302301287651062\n","Training -- 1121/2318 step -- 1.6785701513290405\n","Training -- 1131/2318 step -- 2.0244545936584473\n","Training -- 1141/2318 step -- 2.0505383014678955\n","Training -- 1151/2318 step -- 1.5616776943206787\n","Training -- 1161/2318 step -- 1.8000692129135132\n","Training -- 1171/2318 step -- 1.8578826189041138\n","Training -- 1181/2318 step -- 1.7177879810333252\n","Training -- 1191/2318 step -- 1.499277114868164\n","Training -- 1201/2318 step -- 1.7084308862686157\n","Training -- 1211/2318 step -- 1.5809292793273926\n","Training -- 1221/2318 step -- 1.6718924045562744\n","Training -- 1231/2318 step -- 1.7312560081481934\n","Training -- 1241/2318 step -- 1.8346097469329834\n","Training -- 1251/2318 step -- 1.681288242340088\n","Training -- 1261/2318 step -- 1.68262779712677\n","Training -- 1271/2318 step -- 1.5431236028671265\n","Training -- 1281/2318 step -- 1.3642977476119995\n","Training -- 1291/2318 step -- 2.0528817176818848\n","Training -- 1301/2318 step -- 1.5094431638717651\n","Training -- 1311/2318 step -- 1.7593592405319214\n","Training -- 1321/2318 step -- 1.6181726455688477\n","Training -- 1331/2318 step -- 1.990059494972229\n","Training -- 1341/2318 step -- 1.5748366117477417\n","Training -- 1351/2318 step -- 1.250390648841858\n","Training -- 1361/2318 step -- 1.7288507223129272\n","Training -- 1371/2318 step -- 1.4214997291564941\n","Training -- 1381/2318 step -- 1.7421671152114868\n","Training -- 1391/2318 step -- 1.9809527397155762\n","Training -- 1401/2318 step -- 1.8607362508773804\n","Training -- 1411/2318 step -- 1.6200683116912842\n","Training -- 1421/2318 step -- 1.6562926769256592\n","Training -- 1431/2318 step -- 1.6673288345336914\n","Training -- 1441/2318 step -- 1.175948143005371\n","Training -- 1451/2318 step -- 1.718205451965332\n","Training -- 1461/2318 step -- 1.34405517578125\n","Training -- 1471/2318 step -- 1.7328124046325684\n","Training -- 1481/2318 step -- 2.007075309753418\n","Training -- 1491/2318 step -- 1.6667819023132324\n","Training -- 1501/2318 step -- 1.5872056484222412\n","Training -- 1511/2318 step -- 1.420052409172058\n","Training -- 1521/2318 step -- 1.5224597454071045\n","Training -- 1531/2318 step -- 1.492635726928711\n","Training -- 1541/2318 step -- 1.2278828620910645\n","Training -- 1551/2318 step -- 1.3036742210388184\n","Training -- 1561/2318 step -- 1.1997096538543701\n","Training -- 1571/2318 step -- 1.3085012435913086\n","Training -- 1581/2318 step -- 1.6183981895446777\n","Training -- 1591/2318 step -- 1.7745968103408813\n","Training -- 1601/2318 step -- 1.757155418395996\n","Training -- 1611/2318 step -- 1.379228115081787\n","Training -- 1621/2318 step -- 1.4773786067962646\n","Training -- 1631/2318 step -- 1.8147356510162354\n","Training -- 1641/2318 step -- 1.6444780826568604\n","Training -- 1651/2318 step -- 1.9118728637695312\n","Training -- 1661/2318 step -- 1.8350173234939575\n","Training -- 1671/2318 step -- 1.8069686889648438\n","Training -- 1681/2318 step -- 1.6869840621948242\n","Training -- 1691/2318 step -- 1.8043248653411865\n","Training -- 1701/2318 step -- 1.4258697032928467\n","Training -- 1711/2318 step -- 2.006228446960449\n","Training -- 1721/2318 step -- 1.7387585639953613\n","Training -- 1731/2318 step -- 1.5944466590881348\n","Training -- 1741/2318 step -- 1.6382681131362915\n","Training -- 1751/2318 step -- 1.4440813064575195\n","Training -- 1761/2318 step -- 1.797607421875\n","Training -- 1771/2318 step -- 1.6348246335983276\n","Training -- 1781/2318 step -- 1.9046084880828857\n","Training -- 1791/2318 step -- 1.9030357599258423\n","Training -- 1801/2318 step -- 1.6036970615386963\n","Training -- 1811/2318 step -- 1.4976733922958374\n","Training -- 1821/2318 step -- 1.591177225112915\n","Training -- 1831/2318 step -- 1.589253544807434\n","Training -- 1841/2318 step -- 1.5723581314086914\n","Training -- 1851/2318 step -- 1.4003323316574097\n","Training -- 1861/2318 step -- 1.6789894104003906\n","Training -- 1871/2318 step -- 1.5555155277252197\n","Training -- 1881/2318 step -- 1.40412437915802\n","Training -- 1891/2318 step -- 1.8205652236938477\n","Training -- 1901/2318 step -- 1.6289522647857666\n","Training -- 1911/2318 step -- 1.50843346118927\n","Training -- 1921/2318 step -- 1.2998080253601074\n","Training -- 1931/2318 step -- 1.405024528503418\n","Training -- 1941/2318 step -- 1.5597931146621704\n","Training -- 1951/2318 step -- 1.5807132720947266\n","Training -- 1961/2318 step -- 1.3530707359313965\n","Training -- 1971/2318 step -- 1.5679806470870972\n","Training -- 1981/2318 step -- 1.4145426750183105\n","Training -- 1991/2318 step -- 1.4234458208084106\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fMfc1YAKSCMt","executionInfo":{"status":"ok","timestamp":1622714334750,"user_tz":-540,"elapsed":223,"user":{"displayName":"NAVY_LIGHTS Q","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6Piv3pw8kuU3FwG96XJr1Utla0LhE59_h-rbnBQ=s64","userId":"05414969994838022364"}}},"source":["idx = 0\n","\n","batch_x = x[idx * batch_size: (idx+1)*batch_size]\n","batch_y = y[idx * batch_size: (idx+1)*batch_size]\n","batch_mask = mask[idx * batch_size: (idx+1)*batch_size]\n","batch_nsp = nsp[idx * batch_size: (idx+1)*batch_size]\n","batch_weight = weight[idx * batch_size: (idx+1)*batch_size]\n","batch_segments = segments[idx * batch_size: (idx+1)*batch_size]\n","false_y = np.array([ 0 for _ in range(batch_size)])"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DVrzX2CpSOyM","executionInfo":{"status":"ok","timestamp":1622714346916,"user_tz":-540,"elapsed":9601,"user":{"displayName":"NAVY_LIGHTS Q","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6Piv3pw8kuU3FwG96XJr1Utla0LhE59_h-rbnBQ=s64","userId":"05414969994838022364"}},"outputId":"3bb4e74b-11d8-40f0-b9cc-0fa911153ea5"},"source":["loss = pretrainBert.train_on_batch(x = [batch_x, batch_mask, batch_y, batch_nsp, batch_weight, batch_segments]\n","                                               , y = false_y)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['dense_6/kernel:0', 'dense_6/bias:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['dense_6/kernel:0', 'dense_6/bias:0'] when minimizing the loss.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3Q6PGybHrCbK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622710839056,"user_tz":-540,"elapsed":925566,"user":{"displayName":"NAVY_LIGHTS Q","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6Piv3pw8kuU3FwG96XJr1Utla0LhE59_h-rbnBQ=s64","userId":"05414969994838022364"}},"outputId":"8808ddcc-c92e-474a-ab9f-ea6ba7dc69f4"},"source":["hist = pretrainBert.fit(batch_size = batch_size, epochs = epochs\n","                        , x = [x, mask, y, nsp, masked_lm_weight[:]], y = false_y)"],"execution_count":52,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['dense_46/kernel:0', 'dense_46/bias:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['dense_46/kernel:0', 'dense_46/bias:0'] when minimizing the loss.\n","1563/1563 [==============================] - 891s 567ms/step - loss: 1.6783\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JGCSJn7PrCbL","executionInfo":{"status":"ok","timestamp":1622710839063,"user_tz":-540,"elapsed":23,"user":{"displayName":"NAVY_LIGHTS Q","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6Piv3pw8kuU3FwG96XJr1Utla0LhE59_h-rbnBQ=s64","userId":"05414969994838022364"}}},"source":["pretrainBert.save_weights('/content/qdrive/MyDrive/Data_Backup/210601_Bert_DT_BU/model_weight_1_210603_500000_wi_weight.tf')"],"execution_count":53,"outputs":[]}]}