{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from C:\\Users\\LGCNS\\Documents\\GitHub\\Q_Bert\\QBert\\QBertModel.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from copy import deepcopy\n",
    "\n",
    "import import_ipynb\n",
    "from QBert import QBertModel\n",
    "\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def load_pkl(file_path) :\n",
    "    \n",
    "    with open(file_path, 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def save_pkl(df, file_path) :\n",
    "    \n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(df, f)\n",
    "\n",
    "def create_padding_mask(x):\n",
    "    init_shape = x.shape\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, key의 문장 길이)\n",
    "    return np.array(mask).reshape(init_shape[0], 1,1, init_shape[1])\n",
    "\n",
    "def ind_to_weight(masked_pos, seq_len) :\n",
    "    return tf.reduce_sum(tf.one_hot(masked_pos, seq_len), axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = ['./Test_Examples.tfrecords']\n",
    "raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a description of the features.\n",
    "feature_description = {\n",
    "    'input_ids': tf.io.FixedLenFeature([256], tf.int64),\n",
    "    'segment_ids': tf.io.FixedLenFeature([256], tf.int64),\n",
    "    'input_mask': tf.io.FixedLenFeature([256], tf.int64),\n",
    "    'masked_lm_positions': tf.io.FixedLenFeature([255], tf.int64),\n",
    "    'masked_lm_ids': tf.io.FixedLenFeature([255], tf.int64),\n",
    "    'masked_lm_weights': tf.io.FixedLenFeature([255], tf.float32),\n",
    "    'next_sentence_labels': tf.io.FixedLenFeature([1], tf.int64),\n",
    "}\n",
    "\n",
    "keys = feature_description.keys()\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "  # Parse the input `tf.train.Example` proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: {input_ids: (256,), input_mask: (256,), masked_lm_ids: (255,), masked_lm_positions: (255,), masked_lm_weights: (255,), next_sentence_labels: (1,), segment_ids: (256,)}, types: {input_ids: tf.int64, input_mask: tf.int64, masked_lm_ids: tf.int64, masked_lm_positions: tf.int64, masked_lm_weights: tf.float32, next_sentence_labels: tf.int64, segment_ids: tf.int64}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_dataset = raw_dataset.map(_parse_function)\n",
    "parsed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "siz = 0\n",
    "for raw_record in parsed_dataset.take(1):\n",
    "    raw_one = raw_record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========input_ids========\n",
      "tf.Tensor(\n",
      "[    2  7864 18704   255  3684    12 19411  5673  3325 26078  6281  5659\n",
      "    15  8538  5746  6972    16    13   544  5649     4  6718     4    12\n",
      "    20 12884     4    13 18958  3018  6871     4    32 14583  3105 17853\n",
      "     4  7430     6   541  3091  3273  5661  4334    12 13930  6875  7904\n",
      "  8109     4    15  8277 14197  3113    13     6  5949  7788    17  7720\n",
      "  5697  6025     4   532  3018  3473  3022    12  8088  6215  6375 13595\n",
      "  3036    13  5852     4     4  3090 13912    12     4  8289 13952 11038\n",
      "    13     6  5978 13122  3091 17444 26094    17  5643  7015  2037 14361\n",
      "     4 26214  8442    15  5667  2073 11126 12850     4  8506 12138  2037\n",
      "  7740  5858     4  3018  3473 14629 26570  5742 13122     4 26214     4\n",
      "  5740     4 30333  7021  1727 11761     4    17     3  6080  5771  7352\n",
      "  3267 27778  3169  2073 20156 21302  7521 28753     4 12426 26637     4\n",
      " 26298 18393     4     4     6  7990   150  6258  1886  5584    17 10563\n",
      "  7021 12850 23240  8515 12989     6  5978 10934     4     4  6148  3064\n",
      "  7317  5640    17     3     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0], shape=(256,), dtype=int64)\n",
      "========segment_ids========\n",
      "tf.Tensor(\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(256,), dtype=int64)\n",
      "========input_mask========\n",
      "tf.Tensor(\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(256,), dtype=int64)\n",
      "========masked_lm_positions========\n",
      "tf.Tensor(\n",
      "[146  49  32  75  31 147  26 114 143 165 126 164 117 121  36  22 119 140\n",
      "  76 150  96  62 110 104  20  80   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0], shape=(255,), dtype=int64)\n",
      "========masked_lm_ids========\n",
      "tf.Tensor(\n",
      "[ 3739  6127  3053     6 11341  7250  3207 14919  6220  9348  5592  8186\n",
      "  5616  7239  3787  3105  3021  3130 17853  3024  6309 20438   532  6519\n",
      "  3107 18012     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0], shape=(255,), dtype=int64)\n",
      "========masked_lm_weights========\n",
      "tf.Tensor(\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(255,), dtype=float32)\n",
      "========next_sentence_labels========\n",
      "tf.Tensor([0], shape=(1,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for key in keys :\n",
    "    print(\"========{}========\".format(key))\n",
    "    print(raw_one[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertModule(tf.keras.Model) :\n",
    "\n",
    "    def __init__(self, vocab_size, max_seq_len, num_layers, dff, d_model, num_heads, dropout, name) :\n",
    "        super(BertModule, self).__init__()\n",
    "        self.Bert = qbert_model(vocab_size, max_seq_len, num_layers, dff, d_model, num_heads, dropout, name)\n",
    "        self.vocab_size = vocab_size\n",
    "    \n",
    "    def call(self, inputs) :\n",
    "        \n",
    "        x, mask, lm, nsp, weight, segments = inputs[0], inputs[1], inputs[2], inputs[3], inputs[4], inputs[5]\n",
    "    \n",
    "        bert_outputs = self.Bert([x, mask, segments])\n",
    "\n",
    "        seq_output = bert_outputs['sequence_output']\n",
    "        pooled_output = bert_outputs['pooled_output']\n",
    "        \n",
    "        mask_output = tf.gather_nd(seq_output. weight)\n",
    "        \n",
    "        decoder_w = tf.linalg.pinv(self.Bert.layers[1].weights[0])\n",
    "        \n",
    "        pred_lm =  tf.math.softmax(tf.matmul(seq_output, decoder_w))\n",
    "\n",
    "        true_y_lm = tf.cast(tf.one_hot(tf.cast(lm, dtype = tf.int32), depth = self.vocab_size), dtype = tf.float32)\n",
    "\n",
    "        lm_losses = (tf.reduce_sum(true_y_lm * -tf.math.log(pred_lm), axis = 2))\n",
    "        lm_losses = lm_losses * weight\n",
    "        lm_losses = tf.reduce_mean(lm_losses, axis = 1)\n",
    "\n",
    "        nsp = tf.cast(nsp, dtype = tf.float32)\n",
    "        cls_losses = tf.reduce_mean(tf.reduce_sum(nsp * -tf.math.log(pooled_output), axis = 1))\n",
    "\n",
    "        total_loss = lm_losses + cls_losses\n",
    "\n",
    "        return total_loss\n",
    "    \n",
    "    def get_pretrained_result(self, inputs) :\n",
    "        \n",
    "        x, mask, segments = inputs[0], inputs[1], inputs[2]\n",
    "    \n",
    "        bert_outputs = self.Bert([x, mask, segments])\n",
    "\n",
    "        seq_output = bert_outputs['sequence_output']\n",
    "        pooled_output = bert_outputs['pooled_output']\n",
    "\n",
    "        decode_matrix = tf.linalg.pinv(self.Bert.layers[1].weights[0])\n",
    "\n",
    "        pred_lm =  tf.math.softmax(tf.matmul(seq_output, decode_matrix))\n",
    "        pooled_output = self.dense_cls(seq_output[:, 0])\n",
    "        \n",
    "        return pred_lm, pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = load_pkl('./dt/train_set_under_255.pkl')\n",
    "# train = load_pkl('./dt/train_set-maksed-position-sample-10000.pkl')\n",
    "# train = load_pkl('./dt/train_set-masked-position.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = list(filter(lambda x: len(x['x']) <= 130, train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 32000\n",
    "max_seq_len = 130 # 512\n",
    "num_layers = 6 # 12\n",
    "dff = 384 * 2 # 768 * 4\n",
    "d_model = 384 # 768\n",
    "num_heads = 6 # 12\n",
    "dropout = .1\n",
    "name = 'qbert_210603'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = pad_sequences([ x['x'] for x in train ], max_seq_len, padding = 'post')\n",
    "y = pad_sequences([ x['label'] for x in train ] , max_seq_len, padding = 'post')\n",
    "nsp = np.asarray([ x['NSP'] for x in train ])\n",
    "\n",
    "weight = np.array([ ind_to_weight(x['masked_position'], max_seq_len) for x in train])\n",
    "\n",
    "mask = create_padding_mask(x)\n",
    "\n",
    "segments = np.array([create_segments(i) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "lr = 1e-4\n",
    "batch_size = 32\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrainBert = BertModule(vocab_size, max_seq_len, num_layers, dff, d_model, num_heads, dropout, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrainBert.compile(optimizer=optimizer, loss ='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_y = np.array([ 0 for _ in range(len(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"qbert_210603\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, None, 384)    12288000    inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "position_embedding_2 (PositionE (None, None, 384)    49920       embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "segments (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_28 (TensorFlo [(None, None, 384)]  0           embedding_4[0][0]                \n",
      "                                                                 position_embedding_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, None, 384)    1152        segments[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_29 (TensorFlo [(None, None, 384)]  0           tf_op_layer_AddV2_28[0][0]       \n",
      "                                                                 embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, None, 384)    0           tf_op_layer_AddV2_29[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "padding_mask (InputLayer)       [(None, 1, 1, None)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoding_layer_0 (Model)        (None, None, 384)    1183872     dropout_26[0][0]                 \n",
      "                                                                 padding_mask[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoding_layer_1 (Model)        (None, None, 384)    1183872     encoding_layer_0[1][0]           \n",
      "                                                                 padding_mask[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoding_layer_2 (Model)        (None, None, 384)    1183872     encoding_layer_1[1][0]           \n",
      "                                                                 padding_mask[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoding_layer_3 (Model)        (None, None, 384)    1183872     encoding_layer_2[1][0]           \n",
      "                                                                 padding_mask[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoding_layer_4 (Model)        (None, None, 384)    1183872     encoding_layer_3[1][0]           \n",
      "                                                                 padding_mask[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoding_layer_5 (Model)        (None, None, 384)    1183872     encoding_layer_4[1][0]           \n",
      "                                                                 padding_mask[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_82 (Dense)                (None, None, 384)    147840      encoding_layer_0[1][0]           \n",
      "==================================================================================================\n",
      "Total params: 19,590,144\n",
      "Trainable params: 19,590,144\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrainBert.Bert.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310/310 [==============================] - 5738s 19s/step - loss: 1.9390\n"
     ]
    }
   ],
   "source": [
    "hist = pretrainBert.fit(batch_size = batch_size, epochs = epochs\n",
    "                      , x = [x, mask, y, nsp, masked_lm_weight, segments], y = false_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = '210604'\n",
    "\n",
    "pretrainBert.save_weights('./model/BertPretrained-{}-{}-{}-{}-{}/'.format(today, max_seq_len, num_layers, d_model, num_heads))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1b92d0e1f60>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrainBert.load_weights('./model/BertPretrained-{}-{}-{}-{}-{}/'.format(today, max_seq_len, num_layers, d_model, num_heads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train_set = train[np.random.randint(0, len(train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling BertTokenizerFast.from_pretrained() with the path to a single file or url is deprecated\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "\n",
    "tokenizer_for_load = BertTokenizerFast.from_pretrained('./model/BertTokenizer-6000-32000-vocab.txt'\n",
    "                                                   , strip_accents=False\n",
    "                                                   , lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 반면에 [MASK] ##놀 ##리 ##식 커널 [MASK] ##든 [MASK] 커널 ##이 ##든 전통적인 [MASK] 설계 ##는 하드웨어 [MASK] ##화 계층 ( ##랑의 [MASK] 이나 장치 [MASK] 아래 자원을 숨 ##김 ##으로써 하드웨어 [MASK] 추상 ##화한 ##다 . [SEP] 한 예로 전통적인 시스템에서 물리 메모리 [MASK] 할당 ##할 때 실제 [MASK] 알려 ##주지 않기 때문에 오프 ##셋 ##과 기억 관리 장치를 통해서 ##만 문제를 해결 할 수 있다 . [SEP]'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_statement = ' '.join(tokenizer_for_load.convert_ids_to_tokens(sample_train_set['x']))\n",
    "train_statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 반면에 모 ##놀 ##리 ##식 커널 ##이 ##든 마이크로 커널 ##이 ##든 전통적인 커널 설계 ##는 하드웨어 추상 ##화 계층 ( hal ) 이나 장치 드라이버 아래 자원을 숨 ##김 ##으로써 하드웨어 ##를 추상 ##화한 ##다 . [SEP] 한 예로 전통적인 시스템에서 물리 메모리 ##가 할당 ##할 때 실제 위치를 알려 ##주지 않기 때문에 오프 ##셋 ##과 기억 관리 장치를 통해서 ##만 문제를 해결 할 수 있다 . [SEP]'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_statement = ' '.join(tokenizer_for_load.convert_ids_to_tokens(sample_train_set['label']))\n",
    "train_statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_train_set = train[np.random.randint(0, len(train))]\n",
    "\n",
    "train_x = tf.reshape(sample_train_set['x'], (1, -1))\n",
    "train_x = pad_sequences(train_x, max_seq_len, padding = 'post')\n",
    "mask = create_padding_mask(train_x)\n",
    "\n",
    "segments = tf.reshape(create_segments(train_x[0]), (1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pretrainBert.load_weights('./model/model_weight_2106031943-epoch-1-0-loss-0.707.tf')\n",
    "lm, nls = pretrainBert.get_pretrained_result([train_x, mask, segments])\n",
    "train_statement = ' '.join(tokenizer_for_load.convert_ids_to_tokens(tf.argmax(lm, axis = 2)[0]))\n",
    "train_statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.5398552 , 0.46014476]], dtype=float32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
